{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "87af9fe0",
      "metadata": {
        "id": "87af9fe0"
      },
      "source": [
        "# Fine-tuning mT5 pour la summarisation en français\n",
        "\n",
        "Ce notebook présente étape par étape le fine-tuning d'un modèle mT5 pour générer des résumés en français à partir du jeu de données MLSUM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d2eaa24",
      "metadata": {
        "id": "4d2eaa24"
      },
      "source": [
        "## Installation des dépendances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "141ac9fb",
      "metadata": {
        "id": "141ac9fb"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets rouge_score torch sentencepiece evaluate\n",
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed33e355",
      "metadata": {
        "id": "ed33e355"
      },
      "source": [
        "## Import des bibliothèques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dea3102a",
      "metadata": {
        "id": "dea3102a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import (\n",
        "    MT5ForConditionalGeneration,\n",
        "    MT5Tokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af71ded4",
      "metadata": {
        "id": "af71ded4"
      },
      "source": [
        "## Chargement et préparation du jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8921ec2a",
      "metadata": {
        "id": "8921ec2a"
      },
      "outputs": [],
      "source": [
        "# Chargement du jeu de données MLSUM en français\n",
        "# A peu près 300.000 exemples\n",
        "dataset = load_dataset(\"mlsum\", \"fr\")\n",
        "\n",
        "# Création d'un subset de 10 000 exemples avec split train/test\n",
        "# A augmenter pour un modèle bien entrainé\n",
        "subset = dataset[\"train\"].select(range(10000)).train_test_split(\n",
        "    test_size=0.2,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "#8000 pour entrainer\n",
        "print(subset[\"train\"])\n",
        "\n",
        "#2000 pour tester // ces exemples va plûtot m'ont servir pour évaluation\n",
        "print(subset[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed2ed209",
      "metadata": {
        "id": "ed2ed209"
      },
      "source": [
        "## Configuration des paramètres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b16064",
      "metadata": {
        "id": "b3b16064"
      },
      "outputs": [],
      "source": [
        "MODEL = 'google/mt5-base'\n",
        "BATCH_SIZE = 2 # A modifier si entrainement sur cpu\n",
        "NUM_PROCS = 4\n",
        "EPOCHS = 10 # A modifier si entrainement sur cpu\n",
        "MAX_LENGTH = 768\n",
        "OUT_DIR = 'résultat'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f279910e",
      "metadata": {
        "id": "f279910e"
      },
      "source": [
        "## Tokenizer et fonction de prétraitement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fdcb803",
      "metadata": {
        "id": "4fdcb803"
      },
      "outputs": [],
      "source": [
        "# Initialisation du tokenizer pour le français\n",
        "tokenizer = MT5Tokenizer.from_pretrained(MODEL)\n",
        "tokenizer.src_lang = \"fr_FR\"\n",
        "tokenizer.tgt_lang = \"fr_FR\"\n",
        "tokenizer.add_tokens([\"<2fr>\"], special_tokens=True)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [doc.replace(\"\\n\", \" \").strip()[:2000] for doc in examples[\"text\"]]\n",
        "    targets = [doc.replace(\"\\n\", \" \").strip()[:300] for doc in examples[\"summary\"]]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=MAX_LENGTH,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            targets,\n",
        "            max_length=MAX_LENGTH,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9929868d",
      "metadata": {
        "id": "9929868d"
      },
      "source": [
        "## Prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7626bbd8",
      "metadata": {
        "id": "7626bbd8"
      },
      "outputs": [],
      "source": [
        "# Tokenisation en parallèle\n",
        "tokenized_datasets = subset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=NUM_PROCS,\n",
        "    remove_columns=subset[\"train\"].column_names # garder que les champs tokenized\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc3a77e",
      "metadata": {
        "id": "dbc3a77e"
      },
      "source": [
        "## Chargement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9932ed26",
      "metadata": {
        "id": "9932ed26"
      },
      "outputs": [],
      "source": [
        "# Chargement du modèle mT5\n",
        "model = MT5ForConditionalGeneration.from_pretrained(MODEL)\n",
        "model.to('cuda') #entrainement sur gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb5bd0b0",
      "metadata": {
        "id": "fb5bd0b0"
      },
      "source": [
        "## Définition des métriques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e4490de",
      "metadata": {
        "id": "4e4490de"
      },
      "outputs": [],
      "source": [
        "# Configuration de ROUGE\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Nettoyage pour le français\n",
        "    decoded_preds = [p.replace(\"▁\", \" \").replace(\"  \", \" \").strip() for p in decoded_preds]\n",
        "    decoded_labels = [l.replace(\"▁\", \" \").replace(\"  \", \" \").strip() for l in decoded_labels]\n",
        "\n",
        "    result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True,\n",
        "        rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"]\n",
        "    )\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7960df6e",
      "metadata": {
        "id": "7960df6e"
      },
      "source": [
        "## Configuration de l'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a07e37b7",
      "metadata": {
        "id": "a07e37b7"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=OUT_DIR,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    learning_rate=3e-4,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=500,\n",
        "    logging_dir=f\"{OUT_DIR}/logs\",\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"rougeL\",\n",
        "    greater_is_better=True,\n",
        "    fp16=True,\n",
        "    report_to=\"tensorboard\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d672f6bd",
      "metadata": {
        "id": "d672f6bd"
      },
      "source": [
        "## Création du Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9ddd2f",
      "metadata": {
        "id": "2a9ddd2f"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2108aa1c",
      "metadata": {
        "id": "2108aa1c"
      },
      "source": [
        "## Lancement de l'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1be0b78",
      "metadata": {
        "id": "e1be0b78"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1b416ce",
      "metadata": {
        "id": "b1b416ce"
      },
      "source": [
        "## Génération de résumés et tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e1d9bd",
      "metadata": {
        "id": "c5e1d9bd"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_summary(text):\n",
        "    text = text.encode(\"utf-8\", \"ignore\").decode(\"utf-8\")[:2000]\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(model.device)\n",
        "    print(\"\\nTexte tokenisé:\", tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True))\n",
        "    forced_bos_token_id = tokenizer.convert_tokens_to_ids(\"<2fr>\")\n",
        "    summary_ids = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_length=150,\n",
        "        num_beams=6,\n",
        "        forced_bos_token_id=forced_bos_token_id,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return tokenizer.decode(summary_ids[0].cpu(), skip_special_tokens=True)\n",
        "\n",
        "def test_model_samples(num_samples=3):\n",
        "    test_samples = random.sample(range(len(subset[\"test\"])), num_samples)\n",
        "    for i in test_samples:\n",
        "        text = subset[\"test\"][i][\"text\"]\n",
        "        reference = subset[\"test\"][i][\"summary\"]\n",
        "        generated_summary = generate_summary(text)\n",
        "        print(f\"\\n=== Exemple {i+1}/{num_samples} ===\")\n",
        "        print(f\"Texte original ({len(text)} caractères):\\n{text[:500]}...\")\n",
        "        print(f\"\\nRésumé généré:\\n{generated_summary}\")\n",
        "        print(f\"\\nRésumé référence:\\n{reference}\")\n",
        "        print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# Exécution du test\n",
        "test_model_samples(num_samples=3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
